{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "class SinsoidalPositionalEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, timestep): \n",
    "        #* get the device of the timestep\n",
    "        device = timestep.device \n",
    "        \n",
    "        #* get the half of the dimension\n",
    "        half_dim = self.dim // 2 \n",
    "        \n",
    "        #* calculate the frequency #* 2^i / 10000^(2i/d)\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        \n",
    "        #* calculate the embeddings\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings) \n",
    "        embeddings = timestep[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import math\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up = False, scale_img = False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_ch) #* time embedding\n",
    "        \n",
    "        #* for upsampling blocks\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            if scale_img: \n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1),\n",
    "                )\n",
    "            else:\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.MaxPool2d(2, stride=2)\n",
    "                )\n",
    "                \n",
    "        #* for downsampling blocks\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "            self.transform = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        \n",
    "        #* defining rest of the layers \n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        #self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.down_scale = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        #* first conv \n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.bnorm1(h)\n",
    "        \n",
    "        # #* time embedding\n",
    "        time_emb = self.time_mlp(t)\n",
    "        time_emb = self.relu(time_emb)\n",
    "        \n",
    "\n",
    "        # #* You may have to debug this part and permute the time embedding according to the shape of your input\n",
    "        time_emb = torch.permute(time_emb[(..., ) + (None, ) * 1], (0,2,1,3)) #* (4,1,64) -> (4,1,64,1) -> (4,64,1,1) \n",
    "        \n",
    "        # #* add time embedding to the output of the first conv\n",
    "        h = h + time_emb\n",
    "        \n",
    "        # #* second conv\n",
    "        \n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        h = self.transform(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## * UNet\n",
    "\n",
    "class Diffusion_Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        image_channels = 1  # * grayscale image\n",
    "        down_block_channels = (32, 64, 128, 256)\n",
    "        up_channels = (256, 128, 64, 32)\n",
    "        self.time_emb_dim = 32\n",
    "        out_dim = 1\n",
    "\n",
    "        # * Time Embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinsoidalPositionalEmbeddings(self.time_emb_dim),  # * positional embeddings\n",
    "            nn.Linear(self.time_emb_dim, self.time_emb_dim),  # * linear layer\n",
    "            nn.ReLU(),  # * activation\n",
    "        )\n",
    "\n",
    "        # * Initial Convolution\n",
    "        self.conv0 = nn.Conv2d(\n",
    "            image_channels, down_block_channels[0], kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "        # * Downsampling Blocks\n",
    "        self.downs = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    in_ch=down_block_channels[i],\n",
    "                    out_ch=down_block_channels[i + 1],\n",
    "                    time_emb_dim=self.time_emb_dim,\n",
    "                )\n",
    "                for i in range(len(down_block_channels) - 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # * Upsampling Blocks\n",
    "        self.ups = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    in_ch=up_channels[i],\n",
    "                    out_ch=up_channels[i + 1],\n",
    "                    time_emb_dim=self.time_emb_dim,\n",
    "                    up=True,\n",
    "                    scale_img= False\n",
    "                )\n",
    "                for i in range(len(up_channels) - 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # * Output Convolution\n",
    "        self.outout = nn.Conv2d(up_channels[-1], out_dim, kernel_size=3, padding=1)\n",
    "\n",
    "    # * forward pass\n",
    "    def forward(self, x, t):\n",
    "        # * Ebmedding time\n",
    "        t = self.time_mlp(t)\n",
    "\n",
    "        # * Initial Convolution\n",
    "        x = self.conv0(x)\n",
    "\n",
    "        # * Unet\n",
    "        residual_input = []\n",
    "        counter = 0\n",
    "        # * append the input of each down block to the list\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residual_input.append(x)\n",
    "            counter += 1\n",
    "\n",
    "        # * pop the last element from the list\n",
    "        for up in self.ups:\n",
    "            x = torch.cat((x, residual_input.pop()), dim=1)\n",
    "            x = up(x, t)\n",
    "\n",
    "        # * output\n",
    "        x = self.outout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.randn(4, 1, 28, 28)\n",
    "time_stamp = torch.randn(4, 1)\n",
    "model = Diffusion_Unet()\n",
    "model(image, time_stamp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  3275649\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "SinsoidalPositionalEmbeddings-1                 [1, 1, 32]               0\n",
      "            Linear-2                 [1, 1, 32]           1,056\n",
      "              ReLU-3                 [1, 1, 32]               0\n",
      "            Conv2d-4            [1, 32, 28, 28]             320\n",
      "            Conv2d-5            [1, 64, 28, 28]          18,496\n",
      "              ReLU-6            [1, 64, 28, 28]               0\n",
      "       BatchNorm2d-7            [1, 64, 28, 28]             128\n",
      "            Linear-8                 [1, 1, 64]           2,112\n",
      "              ReLU-9                 [1, 1, 64]               0\n",
      "           Conv2d-10            [1, 64, 28, 28]          36,928\n",
      "             ReLU-11            [1, 64, 28, 28]               0\n",
      "      BatchNorm2d-12            [1, 64, 28, 28]             128\n",
      "           Conv2d-13            [1, 64, 28, 28]          36,928\n",
      "            Block-14            [1, 64, 28, 28]               0\n",
      "           Conv2d-15           [1, 128, 28, 28]          73,856\n",
      "             ReLU-16           [1, 128, 28, 28]               0\n",
      "      BatchNorm2d-17           [1, 128, 28, 28]             256\n",
      "           Linear-18                [1, 1, 128]           4,224\n",
      "             ReLU-19                [1, 1, 128]               0\n",
      "           Conv2d-20           [1, 128, 28, 28]         147,584\n",
      "             ReLU-21           [1, 128, 28, 28]               0\n",
      "      BatchNorm2d-22           [1, 128, 28, 28]             256\n",
      "           Conv2d-23           [1, 128, 28, 28]         147,584\n",
      "            Block-24           [1, 128, 28, 28]               0\n",
      "           Conv2d-25           [1, 256, 28, 28]         295,168\n",
      "             ReLU-26           [1, 256, 28, 28]               0\n",
      "      BatchNorm2d-27           [1, 256, 28, 28]             512\n",
      "           Linear-28                [1, 1, 256]           8,448\n",
      "             ReLU-29                [1, 1, 256]               0\n",
      "           Conv2d-30           [1, 256, 28, 28]         590,080\n",
      "             ReLU-31           [1, 256, 28, 28]               0\n",
      "      BatchNorm2d-32           [1, 256, 28, 28]             512\n",
      "           Conv2d-33           [1, 256, 28, 28]         590,080\n",
      "            Block-34           [1, 256, 28, 28]               0\n",
      "           Conv2d-35           [1, 128, 28, 28]         589,952\n",
      "             ReLU-36           [1, 128, 28, 28]               0\n",
      "      BatchNorm2d-37           [1, 128, 28, 28]             256\n",
      "           Linear-38                [1, 1, 128]           4,224\n",
      "             ReLU-39                [1, 1, 128]               0\n",
      "           Conv2d-40           [1, 128, 28, 28]         147,584\n",
      "             ReLU-41           [1, 128, 28, 28]               0\n",
      "      BatchNorm2d-42           [1, 128, 28, 28]             256\n",
      "  ConvTranspose2d-43           [1, 128, 56, 56]         262,272\n",
      "        MaxPool2d-44           [1, 128, 28, 28]               0\n",
      "            Block-45           [1, 128, 28, 28]               0\n",
      "           Conv2d-46            [1, 64, 28, 28]         147,520\n",
      "             ReLU-47            [1, 64, 28, 28]               0\n",
      "      BatchNorm2d-48            [1, 64, 28, 28]             128\n",
      "           Linear-49                 [1, 1, 64]           2,112\n",
      "             ReLU-50                 [1, 1, 64]               0\n",
      "           Conv2d-51            [1, 64, 28, 28]          36,928\n",
      "             ReLU-52            [1, 64, 28, 28]               0\n",
      "      BatchNorm2d-53            [1, 64, 28, 28]             128\n",
      "  ConvTranspose2d-54            [1, 64, 56, 56]          65,600\n",
      "        MaxPool2d-55            [1, 64, 28, 28]               0\n",
      "            Block-56            [1, 64, 28, 28]               0\n",
      "           Conv2d-57            [1, 32, 28, 28]          36,896\n",
      "             ReLU-58            [1, 32, 28, 28]               0\n",
      "      BatchNorm2d-59            [1, 32, 28, 28]              64\n",
      "           Linear-60                 [1, 1, 32]           1,056\n",
      "             ReLU-61                 [1, 1, 32]               0\n",
      "           Conv2d-62            [1, 32, 28, 28]           9,248\n",
      "             ReLU-63            [1, 32, 28, 28]               0\n",
      "      BatchNorm2d-64            [1, 32, 28, 28]              64\n",
      "  ConvTranspose2d-65            [1, 32, 56, 56]          16,416\n",
      "        MaxPool2d-66            [1, 32, 28, 28]               0\n",
      "            Block-67            [1, 32, 28, 28]               0\n",
      "           Conv2d-68             [1, 1, 28, 28]             289\n",
      "Ignore the error, summary works fine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "model = Diffusion_Unet()\n",
    "model = model.to('cuda')\n",
    "# print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "\n",
    "try :\n",
    "    summary(\n",
    "    model=model,\n",
    "    input_size= [(1, 28, 28), (1,)],\n",
    "    device='cuda',\n",
    "    batch_size=1\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Ignore the error, summary works fine.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
