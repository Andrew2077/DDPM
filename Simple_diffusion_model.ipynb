{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model\n",
    "- data\n",
    "- Foward Pass\n",
    "  - intialize parameters\n",
    "  - forward pass\n",
    "- Backward pass\n",
    "  - U-Net\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.__version__ != \"2.0.0\":\n",
    "    raise Exception(\"Reconnect to the Correct Kernel\")\n",
    "else:\n",
    "    print(\"You are connected to Kernel, Torch Version: \", torch.__version__)\n",
    "\n",
    "\n",
    "IMG_SIZE = 28\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        # transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),  # Scales data into [0,1]\n",
    "        transforms.Lambda(lambda t: (t * 2) - 1),  # Scale between [-1, 1]\n",
    "    ]\n",
    ")\n",
    "reverse_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        # transforms.Lambda(lambda t: t.permute(1, 2, 0)),  # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.0),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"./data\", download=True, transform=data_transforms\n",
    ")\n",
    "dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# * Step 1: create Noise levels, amount of noise to add\n",
    "T = 25\n",
    "START = 0.0001\n",
    "END = 0.02\n",
    "\n",
    "Betas = torch.linspace(START, END, T)\n",
    "\n",
    "# * Step 2: create Alphas, amount of original image\n",
    "Alphas = 1 - Betas\n",
    "\n",
    "# * Step 3: calculate the cumulative product of alphas\n",
    "Alphas_cumprod = torch.cumprod(Alphas, dim=0)\n",
    "\n",
    "# * Step 4: calculate the cumulative product of Alphas but replace the last element with 1\n",
    "Alphas_cumprod_prev = F.pad(Alphas[:-1], (1, 0), value=1)\n",
    "\n",
    "# * Step 5: calculate the sqrt of the reciprocal of alphas\n",
    "Alphas_sqrt_reciprocals = torch.sqrt(1 / Alphas)\n",
    "\n",
    "# * Step 6: calculate the square root of cumulative product of Alphas\n",
    "Alphas_sqrt_cumpord = torch.sqrt(torch.cumprod(Alphas, dim=0))\n",
    "\n",
    "# * Step 7: calculate the square root of one minus cumulative product of Alphas\n",
    "Alphas_sqrt_one_minus_cumprod = torch.sqrt(1 - torch.cumprod(Alphas, dim=0))\n",
    "\n",
    "# * step 8: caclulate the postierior variance\n",
    "postierior_variance = Betas * (1 - Alphas_cumprod_prev) / (1 - Alphas_cumprod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_from_list(list, t, image_shape):\n",
    "    batch_size = t.shape[0] #* get the batch size\n",
    "    out = list.gather(-1, t.cpu()) #* gather the values from the list & move to cpu\n",
    "    #* reshape the output to match the shape of the input.\n",
    "    out = out.reshape(batch_size, *((1,)) * (len(image_shape) - 1)).to(t.device) \n",
    "    return out\n",
    "\n",
    "def Forward_pass(\n",
    "    image, \n",
    "    t, \n",
    "    sqrt_alphas_cumpord,\n",
    "    sqrt_one_minus_alphas_cumpord,\n",
    "    device = \"cpu\",\n",
    "    torch_seed = 42\n",
    "):  \n",
    "    torch.manual_seed(torch_seed)\n",
    "    #* initialize the noise\n",
    "    noise = torch.randn_like(image)\n",
    "    \n",
    "    #* get the sqrt of alphas cumpord at time t\n",
    "    sqrt_alphas_cumpord_t = get_index_from_list(sqrt_alphas_cumpord, t, image.shape)\n",
    "    \n",
    "    #* get the sqrt of one minus alphas cumpord at time t\n",
    "    sqrt_one_minus_alphas_cumpord_t = get_index_from_list(sqrt_one_minus_alphas_cumpord, t, image.shape)\n",
    "    \n",
    "    image_part = sqrt_alphas_cumpord_t.to(device) * image.to(device)\n",
    "    noise_part = sqrt_one_minus_alphas_cumpord_t.to(device) * noise.to(device)\n",
    "    \n",
    "    noisy_image_t = image_part + noise_part\n",
    "    return noisy_image_t, noise_part\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
